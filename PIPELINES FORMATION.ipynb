{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec85992",
   "metadata": {},
   "source": [
    "# PIPELINES FORMATION FOR CLEANING , PREPROCESSING AND TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e309b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff79a5",
   "metadata": {},
   "source": [
    "# 3.1 Data Cleaning & Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e2c4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "bio_df = pd.read_csv(r\"C:\\Users\\Akash\\Desktop\\api_data_aadhar_biometric_0_500000.csv\")\n",
    "demo_df = pd.read_csv(r\"C:\\Users\\Akash\\Desktop\\api_data_aadhar_demographic_0_500000.csv\")\n",
    "enroll_df = pd.read_csv(r\"C:\\Users\\Akash\\Desktop\\api_data_aadhar_enrolment_0_500000.csv\")\n",
    "\n",
    "# Standardisation mapping for legacy state / city names\n",
    "state_mapping = {\n",
    "    'Orissa': 'Odisha',\n",
    "    'Pondicherry': 'Puducherry',\n",
    "    'Gurgaon': 'Gurugram',\n",
    "    'Bangalore': 'Bengaluru'\n",
    "}\n",
    "\n",
    "# Apply cleaning and standardisation to all datasets\n",
    "dfs = [bio_df, demo_df, enroll_df]\n",
    "\n",
    "for df in dfs:\n",
    "    # Clean column names\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "    # Standardise state names\n",
    "    if 'state' in df.columns:\n",
    "        df['state'] = df['state'].replace(state_mapping)\n",
    "\n",
    "    # Parse dates explicitly (DD-MM-YYYY) to avoid ambiguity\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(\n",
    "            df['date'],\n",
    "            format='%d-%m-%Y',\n",
    "            errors='coerce'\n",
    "        )\n",
    "\n",
    "    # Drop records without pincodes (critical for geo-spatial analysis)\n",
    "    if 'pincode' in df.columns:\n",
    "        df.dropna(subset=['pincode'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd98865",
   "metadata": {},
   "source": [
    "# 3.1.5 Dataset Integration (merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d06d53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate biometric data\n",
    "bio_agg = bio_df.groupby(\n",
    "    ['state', 'district', 'pincode'],\n",
    "    as_index=False\n",
    ").agg(\n",
    "    bio_updates=('date', 'count')\n",
    ")\n",
    "\n",
    "# Aggregate demographic data\n",
    "demo_agg = demo_df.groupby(\n",
    "    ['state', 'district', 'pincode'],\n",
    "    as_index=False\n",
    ").agg(\n",
    "    demo_updates=('date', 'count')\n",
    ")\n",
    "\n",
    "# Aggregate enrolment data\n",
    "enroll_agg = enroll_df.groupby(\n",
    "    ['state', 'district', 'pincode'],\n",
    "    as_index=False\n",
    ").agg(\n",
    "    enrol_updates=('date', 'count')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd431ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = bio_agg.merge(\n",
    "    demo_agg,\n",
    "    on=['state', 'district', 'pincode'],\n",
    "    how='outer'\n",
    ").merge(\n",
    "    enroll_agg,\n",
    "    on=['state', 'district', 'pincode'],\n",
    "    how='outer'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d42ddf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "merged_df['total_updates'] = (\n",
    "    merged_df['bio_updates']\n",
    "    + merged_df['demo_updates']\n",
    "    + merged_df['enrol_updates']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58d6dcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30301, 7)\n",
      "                       state  district  pincode  bio_updates  demo_updates  \\\n",
      "0  Andaman & Nicobar Islands  Andamans   744101         20.0          16.0   \n",
      "1  Andaman & Nicobar Islands  Andamans   744103         17.0          12.0   \n",
      "2  Andaman & Nicobar Islands  Andamans   744105         16.0          16.0   \n",
      "3  Andaman & Nicobar Islands  Andamans   744106         14.0          14.0   \n",
      "4  Andaman & Nicobar Islands  Andamans   744107          9.0           9.0   \n",
      "\n",
      "   enrol_updates  total_updates  \n",
      "0            8.0           44.0  \n",
      "1            9.0           38.0  \n",
      "2            7.0           39.0  \n",
      "3            4.0           32.0  \n",
      "4            5.0           23.0  \n"
     ]
    }
   ],
   "source": [
    "print(merged_df.shape)\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a4afd1",
   "metadata": {},
   "source": [
    "# 3.2 Outlier detection and geospatial clustering (using pincode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f542ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83c6b3",
   "metadata": {},
   "source": [
    "# 3.2.1 Outlier Detection (Low & High Activity Zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec14a69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-Activity Outlier Pincodes: 0\n",
      "High-Activity Outlier Pincodes: 8\n"
     ]
    }
   ],
   "source": [
    "# Calculate IQR for total_updates\n",
    "Q1 = merged_df['total_updates'].quantile(0.25)\n",
    "Q3 = merged_df['total_updates'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define thresholds\n",
    "low_threshold = Q1 - 1.5 * IQR\n",
    "high_threshold = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "low_activity_outliers = merged_df[\n",
    "    merged_df['total_updates'] < low_threshold\n",
    "]\n",
    "\n",
    "high_activity_outliers = merged_df[\n",
    "    merged_df['total_updates'] > high_threshold\n",
    "]\n",
    "\n",
    "print(\"Low-Activity Outlier Pincodes:\", low_activity_outliers.shape[0])\n",
    "print(\"High-Activity Outlier Pincodes:\", high_activity_outliers.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f346a0f",
   "metadata": {},
   "source": [
    "# Prepare data for clustering (PINCODE level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f29fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = merged_df[['total_updates']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4101f7",
   "metadata": {},
   "source": [
    "# Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28e64b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5d92ab",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23b77f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 clusters: Very Low, Low, Medium, High activity\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "merged_df['service_cluster'] = kmeans.fit_predict(scaled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af38d6",
   "metadata": {},
   "source": [
    "# Identify Service-Starved Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bd8d988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "High Priority (Service-Starved) Pincodes:\n",
      "[744112 744206 744211 ... 721135 700149 743513]\n"
     ]
    }
   ],
   "source": [
    "# Compute mean activity per cluster\n",
    "cluster_means = merged_df.groupby('service_cluster')['total_updates'].mean()\n",
    "\n",
    "# Cluster with minimum activity\n",
    "low_service_cluster = cluster_means.idxmin()\n",
    "\n",
    "# High priority pincodes\n",
    "high_priority_pincodes = merged_df.loc[\n",
    "    merged_df['service_cluster'] == low_service_cluster,\n",
    "    'pincode'\n",
    "].unique()\n",
    "\n",
    "print(\"\\nHigh Priority (Service-Starved) Pincodes:\")\n",
    "print(high_priority_pincodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4576c3c",
   "metadata": {},
   "source": [
    "# Summary Table (REPORT-READY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0b32565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster Summary:\n",
      "                 pincodes  avg_updates  min_updates  max_updates\n",
      "service_cluster                                                 \n",
      "0                    5482    37.679164         23.0         48.0\n",
      "1                    8221    78.010357         69.0        156.0\n",
      "2                    5169     7.442419          1.0         22.0\n",
      "3                    8262    59.036859         49.0         68.0\n"
     ]
    }
   ],
   "source": [
    "cluster_summary = merged_df.groupby('service_cluster').agg(\n",
    "    pincodes=('pincode', 'nunique'),\n",
    "    avg_updates=('total_updates', 'mean'),\n",
    "    min_updates=('total_updates', 'min'),\n",
    "    max_updates=('total_updates', 'max')\n",
    ")\n",
    "\n",
    "print(\"\\nCluster Summary:\")\n",
    "print(cluster_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc25a136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
